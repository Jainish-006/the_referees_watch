{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c4db0ea",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4d42917",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KernelDensity\n",
    "import cv2\n",
    "from scipy.signal import argrelextrema\n",
    "import time\n",
    "import math\n",
    "import scipy.cluster.hierarchy as hcluster\n",
    "import pandas as pd\n",
    "import os\n",
    "import zipfile\n",
    "from matplotlib.pyplot import plot\n",
    "from sklearn.cluster import DBSCAN\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb30ce2",
   "metadata": {},
   "source": [
    "# Download data from Kaggle (this is several gigs of video)\n",
    "uncomment if data undownloaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6cf06fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -q kaggle\n",
    "# !mkdir ~/.kaggle\n",
    "# #!cp kaggle.json ~/.kaggle/kaggle.json\n",
    "# !echo '{\"username\":\"keeganmoore8\",\"key\":\"667f611262e0c6c107060b7f8dab7fc0\"}' > ~/.kaggle/kaggle.json\n",
    "# !kaggle competitions download -c nfl-impact-detection\n",
    "# !mkdir data\n",
    "# !mv nfl-impact-detection.zip data\n",
    "# zip_ref = zipfile.ZipFile('data/nfl-impact-detection.zip', 'r')\n",
    "# zip_ref.extractall('data')\n",
    "# zip_ref.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bbdc88a",
   "metadata": {},
   "source": [
    "# YOLOv8 download\n",
    "first is downloading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dee02e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git clone https://github.com/RizwanMunawar/yolov8-object-tracking.git\n",
    "# !cd yolov8-object-tracking\n",
    "# !pip install ultralytics==8.0.0\n",
    "# !pip install filterpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7319baa3",
   "metadata": {},
   "source": [
    "# Darknet YOLOv3 and v4 Player detection (obsolete)\n",
    "No longer used, v8 better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90f09999",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = cv2.dnn.readNetFromDarknet('yolov3.cfg', 'yolov3.weights')\n",
    "net = cv2.dnn.readNetFromDarknet('yolov4.cfg', 'yolov4.weights')\n",
    "output_layer_names = net.getLayerNames()\n",
    "output_layer_names = [output_layer_names[i - 1] for i in net.getUnconnectedOutLayers()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84f56229",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def find_players(image):\n",
    "#     box_start_time = time.time()\n",
    "#     buffer = 100\n",
    "#     im_arr = np.array(image)\n",
    "    \n",
    "#     height, width, channels = im_arr.shape\n",
    "#     blob = cv2.dnn.blobFromImage(im_arr[buffer:len(im_arr)-buffer,buffer:len(im_arr[0])-buffer] , 1 / 255.0, (320, 320), swapRB=True, crop=False)\n",
    "#     cv2.imwrite(\"test.png\", im_arr[buffer:len(im_arr)-buffer,buffer:len(im_arr[0])-buffer])\n",
    "#     net.setInput(blob)\n",
    "#     layer_outputs = net.forward(output_layer_names)\n",
    "\n",
    "#     boxes = []\n",
    "#     confidences = []\n",
    "#     class_ids = []\n",
    "\n",
    "#     for output in layer_outputs:\n",
    "#         for detection in output:\n",
    "#             scores = detection[5:]\n",
    "#             class_id = np.argmax(scores)\n",
    "#             confidence = scores[class_id]\n",
    "\n",
    "#             if confidence > 0.1 and detection[2] < .3 and detection[3] < .3:\n",
    "#                 center_x = int(detection[0] * (width-2*buffer))+buffer\n",
    "#                 center_y = int(detection[1] * (height-2*buffer))+buffer\n",
    "#                 w = int(detection[2] * width)\n",
    "#                 h = int(detection[3] * height)\n",
    "\n",
    "#                 x = int(center_x - w / 2)\n",
    "#                 y = int(center_y - h / 2)\n",
    "\n",
    "#                 boxes.append([x, y, w, h])\n",
    "#                 confidences.append(float(confidence))\n",
    "#                 class_ids.append(class_id)\n",
    "\n",
    "#     indices = cv2.dnn.NMSBoxes(boxes, confidences, 0.1, 0.2)\n",
    "#     return boxes, indices, confidences, class_ids, time.time()-box_start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f3525d",
   "metadata": {},
   "source": [
    "## Dated labeller with v3/v4 (obsolete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16881238",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "# for name in ['Sideline']:\n",
    "#     filename = f'data/train/57584_002674_Endzone.mp4'\n",
    "#     vid = imageio.get_reader(filename,  'ffmpeg')\n",
    "#     out = cv2.VideoWriter(f'{name}_out.mp4',fourcc, vid.get_meta_data()['fps'], (len(vid.get_data(0)[0]),len(vid.get_data(0))))\n",
    "#     line_tot_time = 0\n",
    "#     box_tot_time = 0\n",
    "#     time_tot = 0\n",
    "#     count = 0\n",
    "#     start_time = time.time()\n",
    "#     for frame in range(int(vid.get_meta_data()['duration']*vid.get_meta_data()['fps'])):\n",
    "#         count+=1\n",
    "#         frame_time_start = time.time()\n",
    "#         image = Image.fromarray(vid.get_data(frame))\n",
    "#         lines, line_time = find_lines(image)\n",
    "#         line_tot_time+=line_time\n",
    "#         boxes, indices, confidences, class_ids, box_time = find_players(image)\n",
    "#         box_tot_time += box_time\n",
    "#         im_arr = np.array(image)\n",
    "#         for line in lines:\n",
    "#             cv2.line(im_arr,(line[0][0],line[0][1]),(line[1][0],line[1][1]),(255,0,0),2)\n",
    "#         for i in indices:\n",
    "#             box = boxes[i]\n",
    "#             x, y, w, h = box\n",
    "#             label = str(class_ids[i])\n",
    "#             confidence = confidences[i]\n",
    "#             color = (0, 255, 0)\n",
    "#             cv2.rectangle(im_arr, (x, y), (x+w, y+h), color, 2)\n",
    "#         out.write(im_arr)\n",
    "#         time_tot+= time.time()-frame_time_start\n",
    "#     out.release()\n",
    "#     print(f'total time: {time.time()-start_time} seconds')\n",
    "#     print(f'average frame time: {time_tot/count} seconds')\n",
    "#     print(f'line time: {line_tot_time} seconds')\n",
    "#     print(f'box time: {box_tot_time} seconds')\n",
    "#     print(f'drawing time: {time_tot - box_tot_time - line_tot_time} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0635608c",
   "metadata": {},
   "source": [
    "# Field Line Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ef745e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_lines(image):\n",
    "        line_start_time = time.time()\n",
    "        im_arr = np.array(image)\n",
    "        gray = image.convert(\"L\")\n",
    "        gray_arr = np.array(gray)\n",
    "        edges = cv2.Canny(gray_arr,100,150,apertureSize=3)  #Canny to get edge map\n",
    "        lines_list =[]\n",
    "        lines = cv2.HoughLinesP(     #use cv2's hough lines to get possible lines\n",
    "                    edges, # Input edge image\n",
    "                    1, # Distance resolution in pixels\n",
    "                    np.pi/180, # Angle resolution in radians\n",
    "                    threshold=200, # Min number of votes for valid line\n",
    "                    minLineLength=min(image.height, image.width)/6, # Min allowed length of line\n",
    "                    maxLineGap=25 # Max allowed gap between line for joining them\n",
    "                    )\n",
    "        for points in lines:\n",
    "              # Extracted points nested in the list\n",
    "            x1,y1,x2,y2=points[0]\n",
    "            if x2!=x1:     #need special case for vertical lines, infinte slope\n",
    "                slope = (y2-y1)/(x2-x1)\n",
    "                if slope == 0:\n",
    "                    lines_list.append((slope, int(image.width/2), int(y1))) #slope, center_x, center_y\n",
    "                else:\n",
    "                    x_int = (slope*x1-y1)/slope\n",
    "                    y_int = y1-x1*slope\n",
    "                    if x_int > 0 and x_int < image.width:\n",
    "                        lower_point = (x_int, 0)\n",
    "                    else:\n",
    "                        lower_point = (0, y_int)\n",
    "                    wid_int = ((image.height-y2)/slope)+x2\n",
    "                    hei_int = slope*(image.width-x2)+y2\n",
    "                    if hei_int > 0 and hei_int < image.height:\n",
    "                        upper_point = (image.width, hei_int)\n",
    "                    else:\n",
    "                        upper_point = (wid_int, image.height)\n",
    "                    lines_list.append((slope, int((upper_point[0]+lower_point[0])/2), int((upper_point[1]+lower_point[1])/2))) #slope, center_x, center_y\n",
    "            else:\n",
    "                lines_list.append((999999, int(x1), int(image.height/2))) #slope, center_x, center_y\n",
    "        draw_lines = []\n",
    "        thresh = 30\n",
    "        if len(lines_list)>1:    #non-maximal suppression for lines\n",
    "            clusters = hcluster.fclusterdata(lines_list, thresh, criterion=\"distance\")\n",
    "            df = pd.DataFrame(lines_list, index=clusters).sort_index()\n",
    "            real_lines = []\n",
    "            for i in range(1, max(df.index)+1):\n",
    "                curr = df[df.index==i].median(axis=0)\n",
    "                real_lines.append(list(curr))\n",
    "\n",
    "            df2 = pd.DataFrame(real_lines)\n",
    "            df2.at[df2[2]==0,2]=1\n",
    "            df2.insert(3, 'angle', abs(np.arctan(df2[2]/(df2[1]-(df2[1]-(df2[2]/df2[0])))))) #get angles of lines from x-axis\n",
    "            \n",
    "            if len(df2['angle']) != 0:\n",
    "                #cluster angles, then take biggest cluster as the field lines as opposed to other lines\n",
    "                clustering = DBSCAN(eps=.15, min_samples=2).fit(list(zip(df2['angle'], np.zeros(len(df2['angle'])))))\n",
    "                best_ind = -1\n",
    "                best_score = -1\n",
    "                for i in range(len(set(clustering.labels_))):\n",
    "                    if np.count_nonzero(clustering.labels_ == i) > best_score:\n",
    "                        best_score = np.count_nonzero(clustering.labels_ == i)\n",
    "                        best_ind = i\n",
    "                df2 = df2[clustering.labels_[df2.index]==best_ind]\n",
    "                if len(df2.index) < 2:\n",
    "                    print(\"BAD FRAME\")\n",
    "                for x, curr in df2.iterrows():  \n",
    "                    if int(curr[0]) == 999999:\n",
    "                        draw_lines.append(((int(curr[1]), 0), (int(curr[1]), image.height)))\n",
    "                    elif curr[0] == 0:\n",
    "                        draw_lines.append(((0, int(curr[2])), (image.width, int(curr[2]))))\n",
    "                    else:\n",
    "                        draw_lines.append(((int(curr[1]-(curr[2]/curr[0])),0),(int((image.height-curr[2])/curr[0]+curr[1]),image.height)))\n",
    "\n",
    "                        \n",
    "        return draw_lines, time.time()-line_start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9241c2",
   "metadata": {},
   "source": [
    "# Main Function for Line+Player Detection (with v8)\n",
    "creates a video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd845aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "for name in ['Sideline']:\n",
    "    filename = f'data/57584_002674_Sideline.mp4'\n",
    "    vid = imageio.get_reader(filename,  'ffmpeg')\n",
    "    out = cv2.VideoWriter(f'{name}_out.mp4',fourcc, vid.get_meta_data()['fps'], (len(vid.get_data(0)[0]),len(vid.get_data(0))))\n",
    "    line_tot_time = 0\n",
    "    box_tot_time = 0\n",
    "    time_tot = 0\n",
    "    count = 0\n",
    "    start_time = time.time()\n",
    "    #v8 player detection, puts bounding boxes into a torch file:\n",
    "    !python3 yolov8-object-tracking/yolo/v8/detect/detect_and_trk.py model=yolov8m.pt source='data/57584_002674_Sideline.mp4'\n",
    "    t = torch.load('preds.pt')\n",
    "    for frame in range(int(vid.get_meta_data()['duration']*vid.get_meta_data()['fps'])):\n",
    "        count+=1\n",
    "        frame_time_start = time.time()\n",
    "        image = Image.fromarray(vid.get_data(frame))\n",
    "        lines, line_time = find_lines(image) #get lines in frame\n",
    "        line_tot_time+=line_time\n",
    "        boxes = t[frame][0][:, :4]\n",
    "        im_arr = np.array(image)\n",
    "        #draw lines and boxes onto video:\n",
    "        for line in lines:\n",
    "            cv2.line(im_arr,(line[0][0],line[0][1]),(line[1][0],line[1][1]),(0,0,255),2)\n",
    "        for box in boxes:\n",
    "            x, y, x2, y2 = box\n",
    "            x = int(x)\n",
    "            y = int(y)\n",
    "            x2=int(x2)\n",
    "            y2=int(y2)\n",
    "            color = (255, 0, 0)\n",
    "            cv2.rectangle(im_arr, (x, y), (x2, y2), color, 2)\n",
    "        out.write(im_arr)\n",
    "        time_tot+= time.time()-frame_time_start\n",
    "    out.release()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db2fa20",
   "metadata": {},
   "source": [
    "# Helmet Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9610e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 yolov5/detect.py --weights best.pt \\\n",
    "                  --source 'Sideline_out.mp4' \\\n",
    "                  --img 720 \\\n",
    "                  --hide-labels \\\n",
    "                  --save-txt \\\n",
    "                  --save-conf \\\n",
    "                  --project 'out'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139ba4d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
